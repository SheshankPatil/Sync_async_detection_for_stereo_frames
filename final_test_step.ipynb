{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL imports run in python3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import vpi\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths for the main images and the template image\n",
    "main_image_paths = [\n",
    "    'Cropping_model/7.png',  # First main image path\n",
    "    'Cropping_model/8.png'   # Second main image path\n",
    "]\n",
    "template_image_path = 'Cropped_data/1.png'  # Template image path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template matching section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template matching section\n",
    "def template_matching(main_image_path, template, output_prefix, output_dir):\n",
    "    # Load the main image\n",
    "    main_image = cv2.imread(main_image_path)\n",
    "    if main_image is None:\n",
    "        print(f\"Error: Could not load the main image at {main_image_path}.\")\n",
    "        return None\n",
    "\n",
    "    # Convert the main image and template to grayscale\n",
    "    main_gray = cv2.cvtColor(main_image, cv2.COLOR_BGR2GRAY)\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform template matching\n",
    "    result = cv2.matchTemplate(main_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # Define a threshold to consider a match\n",
    "    threshold = 0.87\n",
    "\n",
    "    # Find locations where the result is above the threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "\n",
    "    # If there are no matches, return None\n",
    "    if len(locations[0]) == 0:\n",
    "        print(f\"No match found for image {main_image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Extract the first matched region\n",
    "    top_left = (locations[1][0], locations[0][0])\n",
    "    bottom_right = (top_left[0] + template.shape[1], top_left[1] + template.shape[0])\n",
    "    matched_region = main_image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "\n",
    "    # Resize the matched region to the specified dimensions (1920x1080)\n",
    "    output_width, output_height = 1920, 1080\n",
    "    resized_matched_region = cv2.resize(matched_region, (output_width, output_height))\n",
    "\n",
    "    # Save the resized matched region to a file in the output directory\n",
    "    output_path = os.path.join(output_dir, f'{output_prefix}_matched_region.png')\n",
    "    cv2.imwrite(output_path, resized_matched_region)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background elimination and contour detection with VPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1590751495.py, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 82\u001b[0;36m\u001b[0m\n\u001b[0;31m    return red_count, white_count, output_path\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Background elimination and contour detection with VPI\n",
    "def process_image_vpi(image_path, output_prefix):\n",
    "    # Load the input image\n",
    "    input_image = cv2.imread(image_path)\n",
    "    if input_image is None:\n",
    "        raise ValueError(f\"Error loading image: {image_path}\")\n",
    "\n",
    "    # Convert the image to VPI format\n",
    "    with vpi.Backend.CUDA:\n",
    "        input_vpi = vpi.asimage(input_image, format=vpi.Format.BGR8)\n",
    "\n",
    "        # --- Red Region Detection ---\n",
    "        # Convert to HSV using VPI\n",
    "        hsv_vpi = input_vpi.convert(vpi.Format.HSV8)\n",
    "        hsv_np = hsv_vpi.cpu()\n",
    "\n",
    "        # Define thresholds for red regions\n",
    "        lower_red1 = np.array([0, 150, 150])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([170, 150, 150])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "        # Create red masks using OpenCV\n",
    "        mask_red1 = cv2.inRange(hsv_np, lower_red1, upper_red1)\n",
    "        mask_red2 = cv2.inRange(hsv_np, lower_red2, upper_red2)\n",
    "        red_mask = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "\n",
    "        # --- Bright/White Region Detection ---\n",
    "        # Convert to grayscale using VPI\n",
    "        gray_vpi = input_vpi.convert(vpi.Format.Y8)\n",
    "        gray_np = gray_vpi.cpu()\n",
    "        cv2.imshow(gray_vpi)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Threshold to isolate white regions\n",
    "        _, white_mask = cv2.threshold(gray_np, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Combine red and white masks\n",
    "        combined_mask = cv2.bitwise_or(red_mask, white_mask)\n",
    "\n",
    "        # Apply the combined mask to the input image\n",
    "        result_image = cv2.bitwise_and(input_image, input_image, mask=combined_mask)\n",
    "\n",
    "        # --- Contour Detection ---\n",
    "        contours_red, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_white, _ = cv2.findContours(white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "if len(contour_results) == 2:\n",
    "    total_count1, contour_image1 = contour_results[0]\n",
    "    total_count2, contour_image2 = contour_results[1]\n",
    "\n",
    "    if total_count1 == total_count2:\n",
    "        print(\"Sync\")\n",
    "    else:\n",
    "        print(\"Async\")\n",
    "\n",
    "    # Show contour images side by side\n",
    "    image1 = cv2.imread(contour_image1)\n",
    "    image2 = cv2.imread(contour_image2)\n",
    "    combined_output = np.hstack((image1, image2))\n",
    "    cv2.imshow('Contour Comparison', combined_output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the combined output\n",
    "    combined_output_path = os.path.join(output_dir, 'contour_comparison.png')\n",
    "    cv2.imwrite(combined_output_path, combined_output)\n",
    "else:\n",
    "    print(\"Not enough processed images for comparison.\")\n",
    "\n",
    "        # Draw contours on the result image\n",
    "    output_image = input_image.copy()\n",
    "    cv2.drawContours(output_image, contours_red, -1, (0, 0, 255), 2)  # Red contours\n",
    "    cv2.drawContours(output_image, contours_white, -1, (0, 255, 0), 2)  # White contours\n",
    "\n",
    "        # Save the output image with contours\n",
    "    output_path = f'{output_prefix}_contours.png'\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "\n",
    "        # Return contour counts and the output image path\n",
    "    red_count = len(contours_red)\n",
    "    white_count = len(contours_white)\n",
    "    return red_count, white_count, output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the template image\n",
    "template = cv2.imread(template_image_path)\n",
    "if template is None:\n",
    "    print(\"Error: Could not load the template image.\")\n",
    "    exit()\n",
    "\n",
    "# Process each main image\n",
    "contour_results = []\n",
    "for i, main_image_path in enumerate(main_image_paths):\n",
    "    prefix = f'image_{i + 1}'\n",
    "\n",
    "    # Step 1: Template matching\n",
    "    matched_image_path = template_matching(main_image_path, template, prefix, output_dir)\n",
    "    if matched_image_path is None:\n",
    "        continue\n",
    "\n",
    "    # Step 2: Background elimination and contour detection using VPI\n",
    "    red_count, white_count, contour_image_path = process_image_vpi(matched_image_path, prefix)\n",
    "    contour_results.append((red_count + white_count, contour_image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(contour_results) == 2:\n",
    "    total_count1, contour_image1 = contour_results[0]\n",
    "    total_count2, contour_image2 = contour_results[1]\n",
    "\n",
    "    if total_count1 == total_count2:\n",
    "        print(\"Sync\")\n",
    "    else:\n",
    "        print(\"Async\")\n",
    "\n",
    "    # Show contour images side by side\n",
    "    image1 = cv2.imread(contour_image1)\n",
    "    image2 = cv2.imread(contour_image2)\n",
    "    combined_output = np.hstack((image1, image2))\n",
    "    cv2.imshow('Contour Comparison', combined_output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the combined output\n",
    "    combined_output_path = os.path.join(output_dir, 'contour_comparison.png')\n",
    "    cv2.imwrite(combined_output_path, combined_output)\n",
    "else:\n",
    "    print(\"Not enough processed images for comparison.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
